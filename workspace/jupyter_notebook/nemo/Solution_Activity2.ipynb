{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "918a0573",
   "metadata": {},
   "source": [
    "# Lab Activity 2: Solution Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b166d",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this lab, you are to reproduce the p-tuning and prompt-tuning process for the question-answering task using the CUAD dataset already available. To complete the activity, you are to implement the following steps:\n",
    "\n",
    "- Understand the structure of the CUAD dataset and process the `CUAD_v1.json` file into a training and validation set. You are free to decide the split ratio. More detail is given below.\n",
    "- Setup your P-Tuning Model Config using omegaconf\n",
    "- Create the prompt formatting template and set the task\n",
    "- Set the pre-trained GPT model as `nemo_gpt1.3B_fp16.nemo` \n",
    "- Build the PyTorch lightning trainer and set all hyperparameters\n",
    "- Create the NeMo experiment manager\n",
    "- Run your p-tuning session\n",
    "- Restore your p-tuned model to run inference\n",
    "\n",
    "\n",
    "Part of the code is written for you. You are to complete the rest by filling in the statements with the missing value(s) in the commented areas of the notebook. We recommend consciously setting/modifying the `config.trainer.max_epochs` value as it determines the time to complete the lab. The lab activity should not exceed `45 mins`; therefore, the value of `config.trainer.max_epochs` should be between `1 and 6` as one epoch may take up to `7 mins`. If you plan to exceed these values, run this notebook after the Bootcamp active hours.\n",
    "\n",
    "Note: *You are not expected to get the best result as this activity is for learning. To achieve better results, you can modify parameters: the number of epochs, learning rate, batch size, max step, training, and validation set sample size*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082023f0",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; color:#FF0000; height:40px; text-color:red; font-size:20px\">Before you run this notebook, please close and shut down the kernel of the previous notebooks. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c451fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999400b",
   "metadata": {},
   "source": [
    "# Tasks and Datasets\n",
    "We will be using p-tuning to teach our GPT model to do **Question Answering**.\n",
    "\n",
    "We will be using the [Contract Understanding Atticus Dataset (CUAD) v1](https://www.atticusprojectai.org/cuad). It is a corpus of more than 13,000 labels in 510 commercial legal contracts that have been manually labeled to identify 41 categories of essential clauses that lawyers look for when reviewing contracts in connection with corporate transactions. \n",
    "\n",
    "CUAD is curated and maintained by The Atticus Project, Inc. to support NLP research and development in legal contract review. Analysis of CUAD can be found at https://arxiv.org/abs/2103.06268. Code for replicating the results and the trained model can be found at https://github.com/TheAtticusProject/cuad.\n",
    "\n",
    "To download the CUAD dataset, you can visit the [CUAD v1 website](https://www.atticusprojectai.org/cuad).\n",
    "\n",
    "\n",
    "\n",
    "## CUAD Dataset Structure\n",
    "### Data Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0ab57",
   "metadata": {},
   "source": [
    "```json\n",
    "...\n",
    "{  \n",
    "    \"answers\": {\n",
    "        \"answer_start\": [44],\n",
    "        \"text\": [\"DISTRIBUTOR AGREEMENT\"]\n",
    "    },\n",
    "    \"context\": \"EXHIBIT 10.6\\n\\n DISTRIBUTOR AGREEMENT\\n\\n THIS  DISTRIBUTOR  AGREEMENT (the  \\\"Agreement\\\")  is made    by and between Electric City Corp.,  a Delaware  corporation  (\\\"Company\\\")  and Electric City of Illinois LLC (\\\"Distributor\\\") this 7th day of September, 1999...\",\n",
    "    \"id\": \"LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGREEMENT__Document Name_0\",\n",
    "    \"question\": \"Highlight the parts (if any) of this contract related to \\\"Document Name\\\" that should be reviewed by a lawyer. Details: The name of the contract\",\n",
    "    \"title\": \"LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGREEMENT\"\n",
    "}\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952cc2c8",
   "metadata": {},
   "source": [
    "### Data Fields\n",
    "\n",
    "- **id:** a string feature representing a unique question ID.\n",
    "- **title:** represents domain/topic of discussion or document title.\n",
    "- **context**: represents a group sentences or document where the answer(s) to a question(s) lies. It is possible for a single context to have two or more questions.\n",
    "- **question:** a text that requires an answer from a context.\n",
    "- **answers:** a text list containing a dictionary of responses and the index `(answer_start)` where the answer text starts within a context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d6c7f",
   "metadata": {},
   "source": [
    "More information on CUAD dataset can be found on the [CUAD v1 website](https://www.atticusprojectai.org/cuad) or at the [Hugging Face Datasets page](https://huggingface.co/datasets/cuad).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b0baf",
   "metadata": {},
   "source": [
    "## File Formats\n",
    "\n",
    "The files in CUAD v1 include 1 CSV file, 1 SQuAD-style JSON file, 28 Excel files, 510 PDF files, and 510 TXT files.\n",
    "\n",
    "-  1 master clauses CSV: an 83-column 511-row file. The first column contains the contracts' names corresponding to the PDF and TXT files in the \"full_contracts_pdf\" and \"full_contracts_txt\" folders. The remaining columns have (1) text context (sometimes referred to as clause) and (2) human-input answers that correspond to each of the 41 categories in these contracts. \n",
    "\n",
    "- 1 SQuAD-style JSON: this file is derived from the master clauses CSV to follow the same format as SQuAD 2.0 (https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/), a question answering dataset whose answers are similarly spans of the input text. The exact structure of the JSON format exactly mimics that of SQuAD 2.0 for compatibility with prior work. We also provide Python scripts for processing this data for ease of use.\n",
    "\n",
    "- 28 Excels: a collection of Excel files containing clauses responsive to each category. The first column contains the contracts' names corresponding to the PDF and TXT files in the \"full_contracts_pdf\" and \"full_contracts_txt\" folders. The remaining columns have (1) text context (clause) corresponding to one or more Categories that belong in the same group as identified in the \"Category List\" below, and (2), in some cases, human-input answers that correspond to such text context. Each file is named \"Label Report - [label/group name] (Group [number]).xlsx\"\n",
    "\n",
    "- 510 entire contract PDFs: a collection of the underlying contracts we used to extract the labels. Each file is named \"[document name].pdf\". These contracts are in a PDF format and are not labeled. The entire agreement PDFs contain raw data and are provided for context and reference.\n",
    "\n",
    "- 510 full contract TXTs: a collection of TXT files of the underlying contracts. Each file is named \"[document name].txt\". These contracts are in a plaintext format and are not labeled. The full contract TXTs contain raw data and are provided for context and reference.\n",
    "\n",
    "We will use the SQuAD-style JSON format dataset (CUAD_v1.json) to facilitate work with prior work and existing language models. In this dataset, each contract is broken up into paragraphs. For each provision category, a model must predict the span of text (if any) in that paragraph corresponding to that category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6010967",
   "metadata": {},
   "source": [
    "**Extract from SQuAD-style JSON format of CUAD dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934da1d",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"qas\": [\n",
    "    {\n",
    "      \"answers\": [{ \"text\": \"Promotion and Distribution Agreement\",\"answer_start\": 307 }],\n",
    "      \"id\": \"WHITESMOKE,INC_11_08_2011-EX-10.26-PROMOTION AND DISTRIBUTION AGREEMENT__Document Name\",\n",
    "      \"question\": \"Highlight the parts (if any) of this contract related to \\\"Document Name\\\" that should be reviewed by a lawyer. Details: The name of the contract\",\n",
    "      \"is_impossible\": false\n",
    "    },\n",
    "    {\n",
    "      \"answers\": [{\"text\": \"Distributor\",\"answer_start\": 625 },\n",
    "                  {\"text\": \"Google\",\"answer_start\": 644 },\n",
    "                  {\"text\": \"Google Inc\",\"answer_start\": 644 },\n",
    "                  {\"text\": \"Whitesmoke Inc.\",\"answer_start\": 492 }],\n",
    "      \"id\": \"WHITESMOKE,INC_11_08_2011-EX-10.26-PROMOTION AND DISTRIBUTION AGREEMENT__Parties\",\n",
    "      \"question\": \"Highlight the parts (if any) of this contract related to \\\"Parties\\\" that should be reviewed by a lawyer. Details: The two or more parties who signed the contract\",\n",
    "      \"is_impossible\": false\n",
    "    },\n",
    "    ...............\n",
    "    {\n",
    "      \"answers\": [],\n",
    "      \"id\": \"WHITESMOKE,INC_11_08_2011-EX-10.26-PROMOTION AND DISTRIBUTION AGREEMENT__Agreement Date\",\n",
    "      \"question\": \"Highlight the parts (if any) of this contract related to \\\"Agreement Date\\\" that should be reviewed by a lawyer. Details: The date of the contract\",\n",
    "      \"is_impossible\": true\n",
    "    }\n",
    "  ],\n",
    "  \"context\": \"Exhibit 10.26    CONFIDENTIAL TREATMENT HAS BEEN REQUESTED AS TO CERTAIN PORTIONS OF THIS DOCUMENT.      EACH SUCH PORTION,  WHICH HAS BEEN OMITTED HEREIN AND REPLACED WITH AN ASTERISK [*], HAS BEEN FILED SEPARATELY      WITH THE SECURITIES AND EXCHANGE COMMISSION.     PROMOTION AND DISTRIBUTION AGREEMENT     This Promotion and        Distribution Agreement including all exhibits (collectively referred to as the \\\"Agreement\\\"), effective as of 1    August 2011 (the  \\\"Effective Date\\\"), is made by and between Whitesmoke Inc., with registered offices/principle    place of business at 501 Silverside Road, Suite 105,  Wilmington DE 19809, USA, (\\\"Distributor\\\"),......\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a55687",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### 1. Dataset splitting: Training and Testing Samples\n",
    "\n",
    "- A CuAD dataset in the SQuAD-like JSON format is provided as a single dataset file.\n",
    "- You must split the dataset into separate training and testing subsets to facilitate model training and evaluation.\n",
    "- You can achieve this using the following code snippet, demonstrating the dataset-splitting process.\n",
    "\n",
    "Run the cell below to download the CUAD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043cc9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1C5T6Na63oATxn8rBmZ5YT55mjrs7WTEG&confirm=t\n",
      "To: /workspace/data/CUAD_v1.json\n",
      "100%|██████████████████████████████████████| 40.1M/40.1M [00:01<00:00, 37.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 ../../source_code/dataset_cuad.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31b671d",
   "metadata": {},
   "source": [
    "- Before running the code snippet for dataset splitting, please ensure that the `CUAD_v1.json` dataset file exists in the `/workspace/data` project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca08bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def split_dataset(data, train_ratio):\n",
    "    # Calculate the number of training samples\n",
    "    num_train = int(len(data) * train_ratio)\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_data = data[:num_train]\n",
    "    test_data = data[num_train:]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Set the working directory\n",
    "data_directory = '/workspace/data/'\n",
    "\n",
    "# Define the path to the downloaded CUAD_v1.json dataset \n",
    "# Make sure that the CUAD_v1.json dataset is in the same directory as the script or provide the correct path to it in the cuad_file_path variable.)\n",
    "cuad_file_path = os.path.join(data_directory, 'CUAD_v1.json')\n",
    "\n",
    "# Load the JSON file\n",
    "with open(cuad_file_path) as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# Extract the data from the JSON file\n",
    "data = json_data['data']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_data, test_data = split_dataset(data, train_ratio=0.9)\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "cuad_directory = os.path.join(data_directory, 'cuad')\n",
    "if not os.path.exists(cuad_directory):\n",
    "    os.makedirs(cuad_directory)\n",
    "\n",
    "# Save the train data into a separate JSON file\n",
    "train_file_path = os.path.join(cuad_directory, 'train_dataset.json')\n",
    "with open(train_file_path, 'w') as train_file:\n",
    "    json.dump({'version': json_data['version'], 'data': train_data}, train_file)\n",
    "\n",
    "# Save the test data into a separate JSON file\n",
    "test_file_path = os.path.join(cuad_directory, 'test_dataset.json')\n",
    "with open(test_file_path, 'w') as test_file:\n",
    "    json.dump({'version': json_data['version'], 'data': test_data}, test_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccddb77",
   "metadata": {},
   "source": [
    "### 2. Preprocessing the train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9572d856",
   "metadata": {},
   "source": [
    "The prompt learning dataset loader accepts a list of JSON/dictionary objects or a list of JSON file names where each file contains a collection of JSON objects. Each JSON object must include the field `taskname,` a string identifier for the task the data example corresponds to. They should also have one or more fields corresponding to different sections of the discrete text prompt. The input data might look like:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"taskname\": \"cuad\", \"context\": [CONTEXT_PARAGRAPH_TEXT1], \"question\": [QUESTION_TEXT1], \"answer\": [ANSWER_TEXT1]},\n",
    "    {\"taskname\": \"cuad\", \"context\": [CONTEXT_PARAGRAPH_TEXT2], \"question\": [QUESTION_TEXT2], \"answer\": [ANSWER_TEXT2]},\n",
    "]\n",
    "```\n",
    "\n",
    "These additional fields can be unlimited and will be used to help map different parts of the discrete text input to a prompt template you define."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd2b42",
   "metadata": {},
   "source": [
    "Set the working directory as `WORK_DIR` and the data directory as `CUAD_DIR.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3e7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = '/workspace'\n",
    "CUAD_DIR = \"/workspace/data/cuad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee76f11",
   "metadata": {},
   "source": [
    "Make a directory to store Python scripts for multitask p-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9eec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = os.path.join(WORK_DIR, \"source_code/activity2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60caeeb3",
   "metadata": {},
   "source": [
    "Preprocessing the dataset using the `prompt_learning_cuad_preprocessing.py` script located in the `source_code` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ba01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train split to /workspace/data/cuad/cuad_train.jsonl\n",
      "100%|█████████████████████████████████████| 6039/6039 [00:01<00:00, 4365.20it/s]\n",
      "Saving val split to /workspace/data/cuad/cuad_val.jsonl\n",
      "100%|███████████████████████████████████████| 663/663 [00:00<00:00, 3491.19it/s]\n",
      "Saving test split to /workspace/data/cuad/cuad_test_ground_truth.jsonl\n",
      "100%|█████████████████████████████████████| 2091/2091 [00:00<00:00, 4826.27it/s]\n",
      "Saving test split to /workspace/data/cuad/cuad_test.jsonl\n",
      "100%|█████████████████████████████████████| 2091/2091 [00:00<00:00, 4893.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess cuad data\n",
    "!python $WORK_DIR/source_code/prompt_learning_cuad_preprocessing.py --data-dir {CUAD_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19a302",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "Saving train split to /workspace/data/cuad/cuad_train.jsonl\n",
    "100%|█████████████████████████████████████| 6030/6030 [00:01<00:00, 4969.38it/s]\n",
    "Saving val split to /workspace/data/cuad/cuad_val.jsonl\n",
    "100%|███████████████████████████████████████| 672/672 [00:00<00:00, 5607.01it/s]\n",
    "Saving test split to /workspace/data/cuad/cuad_test_ground_truth.jsonl\n",
    "100%|█████████████████████████████████████| 2091/2091 [00:00<00:00, 6428.90it/s]\n",
    "Saving test split to /workspace/data/cuad/cuad_test.jsonl\n",
    "100%|█████████████████████████████████████| 2091/2091 [00:00<00:00, 6523.13it/s]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310ef922",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"taskname\": \"cuad\", \"context\": \"Exhibit 4.10 MARKETING AND RESELLER AGREEMENT (the \\\"Agreement\\\") THIS AGREEMENT is made and entered into this 20t h day of December 2018 (the \\\"Effective Date\\\"), by and between Todos Medical Ltd., a corporation organized and existing under the laws of the State of Israel, with an address at 1 Hamada St., Rehovot, Israel (\\\"Todos\\\") and Care G. B. Plus Ltd., a corporation organized and existing under the laws of the State of Israel, with an address at Rechov HaYasmin 50, Carmei Yosef, Israel (the \\\"Reseller\\\"). WHEREAS, Todos has developed and owns a proprietary blood screening test for the early detection of certain forms of cancer which consists of a Physician Kit (for collecting blood samples) and a Lab Kit (for separating plasma and mononuclear cells in the blood samples) which consists of an Isolation Kit and an Analysis Kit, all as more fully described on Exhibit A attached hereto (the \\\"Products\\\"), as well as a proprietary algorithm for the analysis of the blood samples data; and WHEREAS, the Reseller is interested in marketing, distributing, and reselling the Products to customers located in and taking delivery in the State of Israel, including the territory of the Palestinian Authority, (the \\\"Territory\\\" and the \\\"Customers\\\"), all in accordance with the terms set forth herein; NOW THEREFORE in consideration of the agreements, covenants, and conditions hereinafter set forth, the parties agree as follows: 1. Grant of Rights 1.1 Subject to the terms and conditions of this Agreement, Todos hereby grants the Reseller a non-sublicensable, non-transferable, exclusive right to distribute and sell the Products to Customers in the Territory; provided, however, that Reseller may sub-license or transfer its distribution rights to a subsidiary or affiliate of the Reseller. The Reseller shall have a right of first refusal to include within this Agreement any additional products developed, manufactured, or sold by the Company following the Effective Date that are not currently included in Exhibit A, and upon the exercise of such right, the term \\\"Products\\\" shall be expanded to mean such additional products as well. For purposes of clarity, the parties agree that upon Todos's development of a blood screening test for colon cancer, such product shall be added to this Agreement and included within the definition of \\\"Products\\\", subject to the Reseller and Todos agreeing on the commercial terms for such product, including the price. 1.2 The Reseller shall not market, distribute, or sell the Products, whether directly or indirectly, to customers outside of the Territory. This Section 1.2 is a fundamental provision of this Agreement. 1.3 Subject to Section 1.4 below, Todos shall not market, distribute, or sell the Products, whether directly or indirectly, to customers inside of the Territory in any manner other than through the Reseller.\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\n1.4 Notwithstanding the grant of exclusivity to the Reseller, nothing herein shall derogate from Todos's right to distribute the Products in the Territory for non-revenue producing purposes such as research, testing, evaluation, proof of concept, and clinical trials. 2. Exclusivity 2.1 The Reseller's exclusive right to market and sell the Products in the Territory is subject to the Reseller achieving the following milestones by the end of each year this Agreement is in effect (the \\\"Annual Milestones\\\"): Year Annual Milestone(s) Year 1 Not Applicable Each Year Thereafter The parties will agree at the beginning of the year on the Annual Milestone for such year 2.2 If the Reseller sells less than 50% of any year's Annual Milestone, Todos, in its sole discretion, may either (a) cancel the Reseller's exclusivity, and market, distribute, and sell the Products in the Territory directly or indirectly through other distributors and resellers, while leaving the Reseller with a non-exclusive right to distribute and sell the Products for the remainder of the term, or (b) terminate the Agreement upon one hundred eighty (180) days prior written notice, provided that the Reseller does not cure its failure to achieve 50% of the applicable year's Annual Milestone within the 180-day notice period. 3. Duties of Todos 3.1 Todos shall provide technical assistance and advice to support the Reseller's preparation of marketing materials, including technical sales literature, catalogs and the like, to be used in the Territory. 3.2 Todos shall provide the Reseller, at no charge, with initial training relating to the efficient use and operation of the Products as well as instruction regarding use of all associated equipment required to effectively carry out the TM-B1 and TM-B2 cancer screening tests. Additionally, Todos will provide the Reseller with training relating to the handling of all blood samples throughout the screening process, and any and all other training, guidance and support reasonably required to sell the Products in the Territory. 3.3 Todos shall provide the Reseller, at no charge, with technical support relating to the use of the Products. 3.4 Todos shall support the Reseller, at no charge, in providing Customers with scientific data supporting the efficacy of the Products. 3.5 Todos is responsible for obtaining AMAR approval from the Israeli Ministry of Health. 3.6 Todos shall comply with all relevant standards of quality assurance and shall ensure that the Products conform to all Israeli standards and certifications.\\n\\n2\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\n3.7 Todos shall appoint a relationship manager, who shall serve as the primary point of contact with Reseller regarding all maters arising from the business relationship contemplated in this Agreement. 3.8 Todos shall be available for periodic meetings with the Reseller to discuss any issues arising in connection with this Agreement. 3.9 Todos shall fulfill with reasonable dispatch all orders received from the Reseller and accepted by Todos. 3.10 Todos shall refer to the Reseller all Product inquiries and sales opportunities in the Territory that come to the attention of Todos. 4. Duties of the Reseller 4.1 The Reseller shall use all commercially reasonable efforts to market, promote, distribute, and sell the Products to Customers in the Territory, and shall, on its own account, provide a trained and competent sales and marketing team for the efficient promotion and sale of the Products. The Reseller shall achieve the commercialization milestones by the dates set forth in the Commercialization Timetable attached hereto as Exhibit C. 4.2 The Reseller shall be responsible for preparing marketing materials, including technical sales literature, catalogs and the like, to be used in the Territory. All marketing materials shall be subject to the prior written approval of Todos. 4.3 Except for AMAR approval which is the responsibility of Todos, the Reseller shall be responsible for obtaining all necessary governmental, regulatory, and other permits and licenses required to distribute and sell the Products in Israel. Todos shall provide the Reseller with all required assistance in this matter in order to obtain the necessary licenses and permits. 4.4 The Reseller shall be responsible for setting up at least one laboratory in the Territory to support the assay protocol (the \\\"Laboratory\\\"), including the provision of a FTIR that is approved by Todos, as further described in Exhibit B. The Reseller shall obtain the prior approval of Todos for all lab equipment. The Reseller will contract with existing certified laboratories in Israel to obtain the blood samples data, subject to the approval by Todos of each such laboratory. 4.5 The Reseller shall be responsible for providing post-sale support services to Customers, and shall, on its own account, provide a trained and competent support team for the efficient support of the Products. The Reseller shall retain a medical doctor to assist with the provision of support services. 4.6 The Reseller shall run a fifty (50) patient pilot trial to evaluate the performance of the Laboratory and the Reseller's support team. 4.7 The Reseller shall follow Todos's protocols in dealing with or handling the Products, including the shipment of blood samples to the laboratory.\\n\\n3\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\n4.8 The Reseller shall, in marketing, selling, and distributing the Products, not make any promises, representations, statements, warranties or guarantees on behalf of Todos or concerning the Products, except as are expressly authorized in writing by Todos. 4.9 The Reseller shall comply at all times with all applicable laws, rules, regulations, and industry standards relating to the storage, packaging, marketing, distribution, laboratory work, and sale of the Products in the Territory. 4.10 The Reseller shall appoint a relationship manager, who shall serve as the primary point of contact with Todos regarding all maters arising from the business relationship contemplated in this Agreement. Todos's relationship manager shall meet with Todo no less frequently than quarterly and provide a status report on the Reseller's commercialization efforts. In addition, the Reseller will promptly bring to the notice of Todos any information which it has or which it may receive in future which is likely to be of interest, benefit, or use to Todos in relation to both the marketing of the Products in the Territory and the future market requirements of Customers. 4.11 The Reseller shall provide Todos with feedback for a least one percent (1%) of the consumed tests, including providing the actual screening result (by a yearly base) of each test. 4.12 The Reseller shall not market, distribute, or sell any product that competes with Products, nor provide services to any direct competitor of Todos. 4.13 The Parties hereby declare and confirm their awareness to the fact that to the date of the signing of this Agreement, Todos has yet to sell a single Product and lacks any and all sales experience and/or knowledge of the matter. The Reseller shall act as a pioneer in the sales department and shall share with Todos all the sales experience and information it shall gather in order to help Todos' with its worldwide sales. 4.14 The Reseller shall be entitled to enter into agreements with its subsidiaries and affiliates to act as sub-distributors and/or selling agents of the Products in the Territory. 4.15 The Reseller herby declares its awareness that Todos has not yet acquired the required AMAR approval for distribution of the Products in the Territory nor FDA approval. 5. Ordering, Pricing, and Payment Procedures 5.1 Non-Binding Forecasts. On the first day of each calendar quarter, the Reseller will provide Todos with a non-binding rolling weekly forecast of the Reseller's estimated Product purchase requirements over the upcoming six months (the \\\"Forecasts\\\"). 5.2 Orders. From time to time as needed, the Reseller shall provide Todos with firm purchase orders for the Products. Each purchase order shall include the name and address of the Customer. All orders are subject to written acceptance by Todos, which acceptance shall be provided unless the order contains terms that differ from the terms set forth in this Agreement. 5.3 Product Price. The Reseller shall be entitled to purchase the Products from Todos for resale to Customers at a price between US$[ ] and US$[ ], with the actual price to be agreed upon by the Parties (the \\\"Product Price\\\"). At the end of each year this Agreement is in effect, the Parties will discuss each party's costs and whether to revise the Product Price. Todos shall provide the Reseller with Products for clinical trials at no charge.\\n\\n4\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\n5.4 Lead Time. The lead time for each Lab Kit is three (3) months, and the lead time for each Physician Kit is one month, provided that Reseller's order for the Products does not deviate from the applicable Forecast by more than ten percent (10%). 5.5 Delivery. Todos shall ship ordered Products to the Reseller within ninety (90) days of Todos's acceptance of the applicable purchase order DAP Reseller's warehouse (Incoterms 2010), provided that Reseller's order for the Products does not deviate from the applicable Forecast by more than ten percent (10%). 5.6 Todos shall provide the Reseller with the screening results and analysis of each customer blood sample data sent to Todos within one business day of receiving the blood sample data. 5.7 Payment for Products. Todos shall invoice the Reseller for all sums due for Products ordered upon shipment of the ordered Products to the Reseller, and the Reseller shall pay such sums by no later than thirty (30) days from the date of shipment. All payments made to Todos shall be in New Israeli Shekels. 5.8 Taxes. Reseller shall be responsible for paying all sales, use, excise, and value-added taxes imposed on the sale or use of the Products. 6. Reporting and Audit Rights 6.1 Books and Records. During the term and for a period of three (3) years following the termination or expiration of this Agreement, the Reseller shall maintain complete books of accounts and records consistent with sound business and accounting principles and practices consistently applied. 6.2 Quarterly Reports. Within fifteen (15) days of the end of each quarter, the Reseller shall provide Todos with a written report of (a) the quantities of Products distributed, sold, or otherwise transferred; the prices at which the Products were sold; and payments received therefore; and (b) the identity and location of all Customers to whom Products were sold, during the preceding quarter (each a \\\"Quarterly Report\\\"). 6.3 Audits. Todos shall have the right to have an inspection and audit of all the relevant accounting and sales books and records of Reseller conducted by an independent auditor reasonably acceptable to both parties. Any such audit shall be upon five (5) days prior written notice and shall be conducted during normal business hours. If any such audit should disclose any material error in the Quarterly Reports or any resale of the Products by Reseller in contravention of the terms of this Agreement, in addition to any other remedies to which Todos shall be entitled, Reseller shall promptly reimburse Todos for the reasonable cost of the audit. 6.4 On-Site Inspections. Todos shall have the right to conduct periodic on-site inspections to ensure the quality control of the cancer screening processes and the Reseller's compliance with Todos's protocols.\\n\\n5\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\n6.5 Medical Device Reporting. The Reseller shall provide Todos with reports of any adverse events and product problems in accordance with the Mandatory Medical Device Reporting regulations of 21 CFR 803. 7. Warranties 7.1 Performance Warranty. Todos warrants that for a period of one (1) year from the date of delivery of each Product to the Reseller, the Product, except for those components that have a shorter expiration date as set forth on Exhibit A, shall perform substantially in accordance with the Product's documentation and specifications, and shall be free from all defects in materials, manufacture, and workmanship. Todos shall correct or repair any reported non-conformity or defect, or replace the non-conforming Product with a Product that conforms to this warranty. 7.2 Non-Infringement. Todos represents and warrants to the Reseller that Todos has full right to produce and sell the Products as contemplated by this Agreement, and that the Reseller's exercise of the resale rights granted herein will not violate any copyright, patent, or other proprietary right of any third party. 7.3 EXCEPT FOR THE EXPRESS WARRANTIES STATED IN THIS SECTION 7, TODOS DISCLAIMS ANY AND ALL WARRANTIES, INLCUDING ANY IMPLIED WARRANTY OR CONDITION OF MERCHANTABLE QUALITY, MERCHANTABILITY, DURABILITY OR FITNESS FOR A PARTICULAR PURPOSE. NO REPRESENTATION OR OTHER AFFIRMATION OF FACT, INCLUDING BUT NOT LIMITED TO STATEMENTS REGARDING PERFORMANCE OF THE PRODUCTS, WHICH IS NOT CONTAINED IN THIS AGREEMENT, SHALL BE DEEMED TO BE A WARRANTY BY TODOS. 8. Insurance. Each party shall carry appropriate and commercially reasonable amounts of insurance adequate for the activities detailed in this Agreement, as well as sufficient levels of all legally mandated insurance, if any. 9. Intellectual Property 9.1 Reseller acknowledges and agrees that any and all proprietary rights, trade secrets, trademarks, trade names, copyrights, patents, know-how, and other intellectual property rights used or embodied in, related to, or associated with the Products, including all developments, modifications, enhancements, improvements, and derivative works thereof, and all documentation with respect thereto, are and shall remain the sole and exclusive property of Todos or its licensors. 9.2 Subject to the terms and conditions of this Agreement, Todos hereby grants Reseller a limited license to use the Todos name and Todos's trademarks, trade names, service marks, logos and related symbols (the \\\"Todos Marks\\\") in the performance of its activities hereunder and in the marketing of the Products in the Territory. The Reseller's use of the Todos Marks shall be subject to Todos's prior approval. The Reseller will use Todos's designated trademarks, trade names, and intellectual property related notices on or in all marketing materials and packaging, and the Reseller shall market and sell the Products under the Todos brand name. The Reseller will not register or take other action with respect to any Todos Mark used anywhere in the world by Todos, except to the extent authorized in writing by Todos in advance.\\n\\n6\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\n9.3 Reseller shall immediately bring to the attention of Todos any improper or wrongful use of Todos's trademarks or other intellectual or commercial property rights which come to the notice of Reseller, and will, in the performance of its duties hereunder, use every effort to safeguard the property rights and interests of Todos, and will, at the request and cost of Todos, take all steps required by Todos to defend such rights. 9.4 Reseller acknowledges that it does not have and that it will not obtain any proprietary interest in the Todos Marks and agrees not to use the same in any other manner and to discontinue all use thereof immediately upon termination of the Agreement. 10. Confidentiality 10.1 Any technical, scientific, design, or commercial information transferred by one Party to the other under this Agreement which is identified as confidential or which may reasonably be deemed to be confidential, shall be considered confidential and shall be maintained in confidence by the receiving party. In addition, each party shall comply with all applicable health care privacy rules and regulations and maintain the confidentiality of all health care and patient information. 10.2 The receiving party shall maintain in confidence and protect the secrecy of all confidential information of the other Party, and agrees that it shall not disclose, transfer, use in an unauthorized manner, copy, or allow access to any such confidential information to any employees, agents, or third parties, except for those who have a need to know such confidential information to fulfill the purposes of this Agreement, and who are bound by contractual obligations of confidentiality and limitation of use sufficient to give effect to this Section 10. In no event shall the receiving party disclose any of the other Party's confidential information to any competitor of the disclosing party. 10.3 The receiving party shall use the same degree of care to avoid publication, unauthorized disclosure, and unauthorized use of such confidential information as it applies with respect to its own confidential information (but no less than reasonable care), and shall take all reasonable care to ensure that such confidential information is not disclosed to third parties, except insofar as: (a) such confidential information is made public by the disclosing party; (b) such confidential information is in the public domain otherwise than as a consequence of a breach of the obligations herein undertaken; or (c) such confidential information was previously and demonstrably known to the receiving party, or was subsequently independently developed. 10.4 The terms of this Agreement shall be deemed to be confidential information. Each party undertakes that it will not make any announcement or issue any circular or other publicity relating to the existence or subject matter of this Agreement, the terms of this Agreement, or the transactions contemplated hereby, without the prior written approval of the other party as to such announcement's/circular's/publicity's content, form, and manner of publication.\\n\\n7\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\n10.5 Each party acknowledges that the unauthorized use, commercialization or disclosure of the other party's confidential information would cause irreparable harm to such other party. The parties acknowledge that remedies at law may be inadequate to redress the actual or threatened unauthorized use, commercialization, or disclosure of such confidential information and that the foregoing restrictions may be enforced by temporary and permanent injunctive relief without necessity of posting bond. In addition, any award of injunctive relief shall include recovery of associated costs and expenses (including reasonable attorneys' fees). 10.6 The provisions of this Section 10 shall survive the expiration or termination of this Agreement. 11. Term and Termination 11.1 This Agreement shall be effective as of the Effective Date and shall continue in effect for a period of five (5) years from the Reseller's first purchase order for Product issued to Todos (the \\\"Initial Term\\\"), unless terminated earlier by one of the parties in accordance with the terms of this Section 11. Upon completion of the Initial Term, provided that the Reseller has achieved the Annual Milestones, the term of the Agreement shall be automatically renewed for an additional five (5) years. Thereafter, at the end of each renewal term, the Agreement shall renew for an additional two (2) years unless one party provides the other party with prior written notice of non-renewal at least sixty (60) days prior to the expiration of the then-current term. 11.2 Notwithstanding anything to the contrary, a party may terminate this Agreement upon the occurrence of any of the following events, and such party shall not be liable to the other party for the proper exercise of such right: (a) The other party materially breaches this Agreement and continues in such breach for thirty (30) days after the non-breaching party has given written notice thereof to the other party; or (b) For a period of ninety (90) consecutive days, the other party is declared to be insolvent or is the subject of bankruptcy or liquidation proceedings, whether compulsory or voluntary, or has a receiver, judicial administrator or similar officer appointed over all or any material part of its assets, or any security holder or encumbrance lawfully takes possession of any property of or in possession of the other party, or if the other party ceases to carry on its business. 12. Limitation of Liability 12.1 IN NO EVENT SHALL EITHER PARTY BE LIABLE TO THE OTHER PARTY FOR ANY INCIDENTAL, CONSEQUENTIAL, INDIRECT, SPECIAL, OR PUNITIVE DAMAGES (INCLUDING, BUT NOT LIMITED TO, LOST PROFITS, BUSINESS INTERRUPTION, LOSS OF BUSINESS INFORMATION OR OTHER PECUNIARY LOSS) REGARDLESS OF WHETHER SUCH LIABILITY IS BASED ON BREACH OF CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY, BREACH OF WARRANTIES, FAILURE OF ESSENTIAL PURPOSE OR OTHERWISE AND EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\\n\\n8\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\n12.2 Except with regard to a breach of confidentiality, a party's indemnification obligations hereunder, or infringement of intellectual property rights, either party's total liability to the other party under this Agreement shall be limited to the amounts paid or payable by the Reseller to Todos during the twelve-month period preceding the interposition of the claim. 13. Indemnification 13.1 Todos's Duty to Indemnify. Todos shall defend against any claim or lawsuit by a third party (a \\\"Claim\\\") against Reseller to the extent such Claim alleges that the Products infringe any patent, copyright, or trademark or misappropriate a trade secret of a third party, and will indemnify Reseller against all costs, damages, losses, liabilities and expenses (including reasonable attorneys' fees and costs) (\\\"Damages\\\") awarded against Reseller by a court of competent jurisdiction, or agreed to in a written settlement agreement signed by Todos, arising out of such Claim. Todos shall have no indemnification obligation or other liability for any Claim of infringement arising from (a) use of the Products other than in accordance with this Agreement; (b) modification of the Products or the combination of the Products with any other products, services, or materials if the Products would not be infringing without such modification or combination; or (c) any third party products, services, or materials. If Reseller's use of the Products under the terms of this Agreement is enjoined or Todos determines that such use may be enjoined, then Todos may, at its sole option and expense, either (i) procure for Reseller a license to continue using the Products in accordance with the terms of this Agreement; (ii) replace or modify the allegedly infringing Products to avoid the infringement; or (iii) terminate this Agreement. 13.2 Reseller's Duty to Indemnify. Reseller agrees to defend any Claim against Todos (i) that the Reseller's actions infringe any third party patent, or copyright, or any other proprietary right; or (ii) arising out of any act or omission by Reseller relating to the Products. Reseller will indemnify Todos (and its directors, employees and agents) against all Damages awarded against Todos or agreed to in a written settlement agreement signed by Reseller arising out of such Claim. 13.3 General Indemnity. Each party shall defend and indemnify the other party and its employees, officers, directors and agents against all Damages for Claims for bodily injury, death, or damage to real property or tangible physical equipment, proximately caused by the indemnifying Party in the course of performing this Agreement. 13.4 Conditions to Indemnification. The obligations set forth in this Section 13 shall apply only if (i) the indemnified Party promptly notifies the indemnifying Party in writing of a claim upon learning of or receiving the same; (ii) the indemnified Party provides the indemnifying Party with reasonable assistance requested by the indemnifying Party, at the indemnifying Party's expense, for the defense and settlement, if applicable, of any claim; and (iii) the indemnified Party provides the indemnifying Party with the exclusive right to control and the authority to settle any claim. 13.5 Sole and Exclusive Remedies. THE RIGHTS AND OBLIGATIONS IN THIS SECTION 13 ARE THE INDEMNIFYING PARTY'S SOLE AND EXCLUSIVE OBLIGATIONS, AND THE INDEMNIFIED PARTY'S SOLE AND EXCLUSIVE REMEDIES, WITH RESPECT TO ANY SUCH CLAIMS.\\n\\n9\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\n14. Relationship of the Parties The parties to this Agreement are independent contractors. No relationship of principal to agent, master to servant, employer to employee, or franchisor to franchisee is established hereby between the parties. Neither party has the authority to bind the other or incur any obligation on the other's behalf. Any agreement for the sale of Products negotiated or executed between the Reseller and a Customer shall be binding upon the Reseller alone. The Reseller is not authorized to, and shall not, enter into any contracts nor make any other commitments on behalf of or in the name of Todos, unless expressly authorized in writing to do so by Todos. Reseller shall not incur any liabilities, obligations, or commitments on behalf of Todos. 15. Miscellaneous 15.1 Entire Agreement. This Agreement, including its exhibits, constitutes the entire agreement between the parties concerning the subject matter hereof, and supersedes all prior or contemporaneous statements, representations, discussions, negotiations, and agreements, both oral and written. 15.2 Amendments or Waiver. This Agreement may not be amended or modified except in a writing signed by authorized officers of both parties. No order, invoice, or similar document will modify the terms of this Agreement even if accepted by the receiving party. 15.3 Severability. In the event that any one or more of the provisions of this Agreement shall be found to be illegal or unenforceable, this Agreement shall nevertheless remain in full force and effect, and such term or provision shall be deemed severed unless such severance defeats the purpose of this Agreement or results in substantial injustice to one of the parties. 15.4 No Waiver. Neither of the party's rights to enforce provisions of this Agreement shall be affected by any prior course of dealing, waiver, delay, omission, or forbearance. 15.5 Assignment. This Agreement and the rights granted hereunder shall not be assigned, encumbered by security interest or otherwise transferred by the Reseller without the prior written consent of Todos, except for the assignment or transfer of rights to a subsidiary company or an affiliated company. 15.6 Governing Law. This Agreement shall be governed by and construed in accordance with the laws of the State of Israel, and the courts of Tel-Aviv, Israel 15.7 Arbitration. Any dispute, controversy, or claim relating to, connected with, or arising out of this Agreement, including any question regarding its existence, validity, or termination, shall be referred to and finally resolved by arbitration in accordance with the Arbitration Law, before a single arbitrator to agreed upon by both parties and in lack of such agreement as to the identity of the arbitrator, each side shall be eligible, within 7 days of any notice given by any party to the other, to request that the head of the Tel-Aviv Bar Association appoint said arbitrator. [Remainder of Page Left Blank]\\n\\n10\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\nIN WITNESS WHEREOF, the parties have caused this Agreement to be executed by their duly authorized representatives. Todos Medical Ltd. Care G. B. Plus Ltd. /s/ Herman Weiss /s/ Assaf Gold Name: Herman Weiss Name: Assaf Gold Title: CEO Title: Manager Date: 20/12/2018 Date: 20/12/2018 Lists of Exhibits: Exhibit A: The Products Exhibit B: The Laboratory Exhibit C: Commercialization Timetable\\n\\n11\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\nEXHIBIT A THE PRODUCTS Each unit of Product consists of one Physician Kit and one Laboratory Kit. TM-B1 breast cancer screening test and TB-B2 breast cancer diagnostic test General Information: Physician Kit: Laboratory Kit: The Laboratory Kit consists of the Isolation Kit and the Analysis Kit. Isolation Kit: Item 7 (page 8) in the \\\"Isolation Kit\\\" are items that are not provided with the kit and the Reseller is responsible to purchase these items. Analysis Kit: Item 7 (page 8) in the \\\"Analysis Kit\\\" are the items that are not provided with the kit and the Reseller is responsible to purchase these items. Components with an expiration date: [please insert]\\n\\n12\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\nEXHIBIT B THE LABORATORY [please insert description of the laboratory and its components]\\n\\n13\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\\n\\n\\n\\n\\n\\nEXHIBIT C COMMERCIALIZATION TIMETABLE Milestone Target Date Todos to obtain AMAR approval Q3 2019 Reseller to set-up a diagnostic Laboratory (internal or external) that complies with the requirements in the TM-B2 Isolation Kit Instruction for Use. Q3 2019 Reseller to commence 30-50 Women Pilot Trial.  Isolation at Reseller's lab, and FTIR analysis at Todos's facility. Q3 2019 Reseller to commence commercial sales. Q4 2019 Todos to provide kits and computer analysis of files. Q4 2019 14\\n\\nSource: TODOS MEDICAL LTD., 20-F, 3/28/2019\", \"question\": \"Highlight the parts (if any) of this contract related to \\\"Document Name\\\" that should be reviewed by a lawyer. Details: The name of the contract\", \"answer\": \"MARKETING AND RESELLER AGREEMENT\"}\n"
     ]
    }
   ],
   "source": [
    "# What the cuad dataset looks like after processing\n",
    "!head -1 $CUAD_DIR/cuad_train.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bab9c",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "{\"taskname\": \"cuad\", \"context\": \"Exhibit 10.2 PORTIONS OF THIS EXHIBIT MARKED BY [**] HAVE BEEN OMITTED PURSUANT TO RULE 601(B)(10) OF REGULATION S-K. THE OMITTED INFORMATION IS (I) NOT MATERIAL AND (II) WOULD LIKELY CAUSE COMPETITIVE HARM TO THE REGISTRANT IF PUBLICLY DISCLOSED. EXECUTION VERSION STRATEGIC ALLIANCE AGREEMENT STRATEGIC ALLIANCE AGREEMENT, dated as of December 20, 2019 (as amended, supplemented or otherwise modified from time to time, this \\\"Agreement\\\"), by and among Farids & Co. LLC, a Delaware limited liability company (\\\"Farids\\\"), Edible Arrangements, LLC, a Delaware limited liability company (\\\"EA\\\"), and Rocky Mountain Chocolate Factory, Inc., a Delaware corporation (the \\\"Company\\\"). W I T N E S S E T H: WHEREAS, the Company is an international franchisor, confectionery manufacturer and retail operator; WHEREAS, Farids is a holding company and, together with TF (as defined below), indirectly controls EA; WHEREAS, EA is a US-based franchisor that specializes in fresh fruit arrangements and specialty fruit gift items; WHEREAS, the Company desires to issue and sell,...If the foregoing applies, the Parties shall use all reasonable endeavours to agree within a reasonable time upon any lawful and reasonable  variations to the     18\\n\\n\\n\\n\\n\\n     Agreement which may be necessary in order to achieve, to the greatest extent possible, the same effect as would have been achieved by  the Clause, or the part of the Clause, in question.     22 GOVERNING LAW     22.1 This Agreement is governed by English law.     22.2 The Parties submit to the non-exclusive jurisdiction of the courts of England and Wales.     This Agreement shall come into force on the date given at the beginning of this Agreement.\\n\\n   19\\n\\nSIGNED by\\n\\n   )        )  (name),                     )   a duly authorised signatory of     ) (signature)  SHBV (HONG KONG) LTD            )\\n\\nSIGNED by\\n\\n      )           )  (name),\\n\\n\\n\\n\\n\\n     )\\n\\na duly authorised signatory of     ) (signature)  WASTE2ENERGY GROUP HOLDINGS PLC      )\", \"question\": \"Highlight the parts (if any) of this contract related to \\\"Document Name\\\" that should be reviewed by a lawyer. Details: The name of the contract\",\"answer\": \"STRATEGIC ALLIANCE AGREEMENT, d\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008bd1a1",
   "metadata": {},
   "source": [
    "We made a `.jsonl` file for each train, validation, and testing split of the cuad data. Every `.jsonl` file contains JSON objects with the fields `taskname,` `context,` `question,` and `answer.` The preprocessing script is called `prompt_learning_cuad_preprocessing.py.`\n",
    "The CUAD dataset comprises a collection of contract-related questions and answers. It consists of various contracts like \"LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGREEMENT\", \"WHITESMOKE, INC_11_08_2011-EX-10.26-PROMOTION AND DISTRIBUTION AGREEMENT\", and \"MetLife, Inc. - Remarketing Agreement.\" Each contract has a title and paragraph associated with it, and each paragraph has several related questions and answers. When we separated the train/validation/test splits, we separated them on the title level. For example, if the training set contains paragraphs and questions about the contract `LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGREEMENT`, neither the validation nor test samples will have any questions on this contract. All questions about a specific contract are isolated to one data split.\n",
    "\n",
    " (Like the Financial PhraseBank Dataset, we randomly selected 80% of the questions for training, 10% for validation, and 10% for testing. The process resulted in `69125` test examples, `8952` validation, and `8744` testing examples. The `answer` field was removed from test examples.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31166f39",
   "metadata": {},
   "source": [
    "Training on the whole train split could take a lot of time, so we will clip the train set to 1.5k examples for this lab activity and limit the validation dataset to 150 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53cf2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -1500 $CUAD_DIR/cuad_train.jsonl > $CUAD_DIR/cuad_short_train.jsonl\n",
    "! head -150 $CUAD_DIR/cuad_val.jsonl > $CUAD_DIR/cuad_short_val.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef18b9",
   "metadata": {},
   "source": [
    "## P-Tuning Model Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18339fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load the example config file so we can start editing it\n",
    "CONFIG_PATH = os.path.join(WORK_DIR, \"source_code/activity2/conf/megatron_gpt_prompt_learning_config.yaml\")\n",
    "config = OmegaConf.load(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7fc4c",
   "metadata": {},
   "source": [
    "Set the train and validation dataset in the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b165481",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.data.train_ds = [f\"{CUAD_DIR}/cuad_short_train.jsonl\"]\n",
    "config.model.data.validation_ds = [f\"{CUAD_DIR}/cuad_short_val.jsonl\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29184e0",
   "metadata": {},
   "source": [
    "### Prompt Formatting\n",
    "\n",
    "- Add value to:  \n",
    "```bash\n",
    "      \"taskname\": \"\",\n",
    "     \"prompt_template\": \"\",\n",
    "     ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcec7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.task_templates = [\n",
    "    {\n",
    "        \"taskname\": \"cuad\",\n",
    "        \"prompt_template\": \"<|VIRTUAL_PROMPT_0|> Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:{answer}\",\n",
    "        \"total_virtual_tokens\": 15,\n",
    "        \"virtual_token_splits\": [15],\n",
    "        \"truncate_field\": \"context\",\n",
    "        \"answer_only_loss\": True,\n",
    "        \"answer_field\": \"answer\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3983d8",
   "metadata": {},
   "source": [
    "### Setting New Tasks\n",
    "\n",
    "You do this by setting the config file's `new_tasks` and `existing_tasks` values. Because we are p-tuning a model with no existing tasks, you should set `existing_tasks=[]` and `new_tasks=[\"cuad\"]` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1ebe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.existing_tasks = []\n",
    "config.model.new_tasks = [\"cuad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b247440",
   "metadata": {},
   "source": [
    "### Setting The Pre-Trained GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b936a96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PretrainedModelInfo(\n",
       " \tpretrained_model_name=megatron_gpt_345m,\n",
       " \tdescription=345M parameter GPT generative Megatron model.,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/megatron_gpt_345m/versions/1/files/megatron_gpt_345m.nemo\n",
       " )]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what GPT .nemo models we have available on NGC\n",
    "from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel\n",
    "MegatronGPTModel.list_available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b389a",
   "metadata": {},
   "source": [
    "Download the `nemo_gpt1.3B_fp16.nemo` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e28107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mTQjczmQQTm-TL0lxxfzoq3EEFoKQ2l6&confirm=t\n",
      "To: /workspace/source_code/nemo_gpt1.3B_fp16.nemo\n",
      "100%|██████████████████████████████████████| 3.02G/3.02G [00:56<00:00, 53.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "gpt_file_name = \"nemo_gpt1.3B_fp16.nemo\"\n",
    "PRETRAINED_MODEL_DIR = os.path.join(WORK_DIR, \"source_code\")\n",
    "\n",
    "# download the nemo_gpt1.3B_fp16.nemo\n",
    "!python3 ../../source_code/megatron-gpt-model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733566ec",
   "metadata": {},
   "source": [
    "- Now that you have a `.nemo` GPT file, please add its path to the prompt learning config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "402522ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPT model path on prompt learning config\n",
    "config.model.language_model_path = f'{PRETRAINED_MODEL_DIR}/nemo_gpt1.3B_fp16.nemo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13bdf7",
   "metadata": {},
   "source": [
    "- Set checkpoint behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13d47c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.exp_manager.checkpoint_callback_params.save_nemo_on_train_end= True\n",
    "config.exp_manager.checkpoint_callback_params.always_save_nemo= True\n",
    "config.exp_manager.checkpoint_callback_params.save_best_model= True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca9bea",
   "metadata": {},
   "source": [
    "### Setting P-Tuning Specific Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a54fd216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the virtual prompt style to p-tuning (already set by default)\n",
    "config.model.virtual_prompt_style = \"p-tuning\"\n",
    "\n",
    "\n",
    "config.model.p_tuning.dropout = 0.0\n",
    "config.model.p_tuning.num_layers = 2\n",
    "config.model.global_batch_size = 2\n",
    "config.model.micro_batch_size = 1\n",
    "config.model.max_seq_length = 10240  # you can adjust to the squence length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014cbc3",
   "metadata": {},
   "source": [
    "Let's have a look at all the values you've set in the model config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acef6619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 1234\n",
      "nemo_path: ${name}.nemo\n",
      "virtual_prompt_style: p-tuning\n",
      "tensor_model_parallel_size: 1\n",
      "pipeline_model_parallel_size: 1\n",
      "global_batch_size: 2\n",
      "micro_batch_size: 1\n",
      "validation_global_batch_size: ${model.global_batch_size}\n",
      "validation_micro_batch_size: ${model.micro_batch_size}\n",
      "validation_drop_last: false\n",
      "restore_path: null\n",
      "language_model_path: /workspace/source_code/nemo_gpt1.3B_fp16.nemo\n",
      "save_nemo_on_validation_end: true\n",
      "existing_tasks: []\n",
      "new_tasks:\n",
      "- cuad\n",
      "sequence_parallel: false\n",
      "activations_checkpoint_granularity: null\n",
      "activations_checkpoint_method: null\n",
      "activations_checkpoint_num_layers: null\n",
      "task_templates:\n",
      "- taskname: cuad\n",
      "  prompt_template: '<|VIRTUAL_PROMPT_0|> Context: {context}\n",
      "\n",
      "\n",
      "    Question: {question}\n",
      "\n",
      "\n",
      "    Answer:{answer}'\n",
      "  total_virtual_tokens: 15\n",
      "  virtual_token_splits:\n",
      "  - 15\n",
      "  truncate_field: context\n",
      "  answer_only_loss: true\n",
      "  answer_field: answer\n",
      "prompt_tuning:\n",
      "  new_prompt_init_methods:\n",
      "  - text\n",
      "  new_prompt_init_text:\n",
      "  - some init text goes here\n",
      "p_tuning:\n",
      "  encoder_type: tpmlp\n",
      "  dropout: 0.0\n",
      "  num_layers: 2\n",
      "  encoder_hidden: 2048\n",
      "  init_std: 0.023\n",
      "data:\n",
      "  train_ds:\n",
      "  - /workspace/data/cuad/cuad_short_train.jsonl\n",
      "  validation_ds:\n",
      "  - /workspace/data/cuad/cuad_short_val.jsonl\n",
      "  add_eos: true\n",
      "  shuffle: true\n",
      "  num_workers: 8\n",
      "  pin_memory: true\n",
      "  train_cache_data_path: null\n",
      "  validation_cache_data_path: null\n",
      "  test_cache_data_path: null\n",
      "  load_cache: false\n",
      "  max_seq_length: 1024\n",
      "  min_seq_length: 1\n",
      "optim:\n",
      "  name: fused_adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.01\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.98\n",
      "  sched:\n",
      "    name: CosineAnnealing\n",
      "    warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "max_seq_length: 10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final model config\n",
    "print(OmegaConf.to_yaml(config.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d015a705",
   "metadata": {},
   "source": [
    "## Building the PyTorch Lightning Trainer\n",
    "\n",
    "*Tips:* \n",
    "- *Check the Multitask Prompt-tuning and P-tuning notebook*\n",
    "- *Set the `config.trainer.max_epochs` to values from 1 to 5 (each epoch takes approximately 7mins running on an A100 MIG instance (32GB))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3f788b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer config - \n",
      "\n",
      "devices: 1\n",
      "accelerator: gpu\n",
      "num_nodes: 1\n",
      "precision: 16\n",
      "logger: false\n",
      "enable_checkpointing: false\n",
      "replace_sampler_ddp: false\n",
      "max_epochs: 5\n",
      "max_steps: -1\n",
      "log_every_n_steps: 10\n",
      "val_check_interval: 1.0\n",
      "gradient_clip_val: 1.0\n",
      "resume_from_checkpoint: null\n",
      "benchmark: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from nemo.collections.nlp.parts.nlp_overrides import NLPDDPStrategy\n",
    "from pytorch_lightning.plugins.environments import TorchElasticEnvironment\n",
    "\n",
    "# let's modify some trainer configs\n",
    "# check if we have GPU available and uses it\n",
    "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "config.trainer.accelerator = accelerator\n",
    "config.trainer.devices = 1\n",
    "\n",
    "####### Set from 5 to 10 epochs. Each epoch takes approximately 7mins running on A100 MIG instance(32GB) ########\n",
    "config.trainer.max_epochs = 5  \n",
    "##########################################################################################################\n",
    "config.trainer.val_check_interval = 1.0\n",
    "\n",
    "# for PyTorch Native AMP set precision=16\n",
    "config.trainer.precision = 16 if torch.cuda.is_available() else 32\n",
    "\n",
    "# setup cluster environment parameters\"\n",
    "# use torch elastic cluster environment so `create_process_externally` is True\n",
    "# the launcher is set to None. It will not try to spawn new processes.\n",
    "# It won't create the misconfiguration error because of the `interactive session`\n",
    "os.environ[\"LOCAL_RANK\"] = '0'\n",
    "os.environ[\"RANK\"] = '0'\n",
    "os.environ[\"WORLD_SIZE\"] = '1'\n",
    "\n",
    "strategy = NLPDDPStrategy(find_unused_parameters=False,no_ddp_communication_hook=True)\n",
    "plugins = [TorchElasticEnvironment()]\n",
    "trainer = pl.Trainer(plugins= plugins, strategy=strategy, **config.trainer)\n",
    "\n",
    "print(\"Trainer config - \\n\")\n",
    "print(OmegaConf.to_yaml(config.trainer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf1d3b3",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "...\n",
    "Trainer config - \n",
    "\n",
    "devices: 1\n",
    "accelerator: gpu\n",
    "num_nodes: 1\n",
    "precision: 16\n",
    "logger: false\n",
    "enable_checkpointing: false\n",
    "replace_sampler_ddp: false\n",
    "max_epochs: 30\n",
    "max_steps: -1\n",
    "log_every_n_steps: 10\n",
    "val_check_interval: 1.0\n",
    "gradient_clip_val: 1.0\n",
    "resume_from_checkpoint: null\n",
    "benchmark: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb9b100",
   "metadata": {},
   "source": [
    "## Setting up a NeMo Experiment\n",
    "\n",
    "NeMo has an experiment manager that handles logging and checkpointing for us, so let's use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c22a8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:17:46 exp_manager:374] Experiments will be logged at /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-17_09-17-46\n",
      "[NeMo I 2023-11-17 09:17:46 exp_manager:797] TensorboardLogger has been set up\n",
      "/workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-17_09-17-46\n"
     ]
    }
   ],
   "source": [
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "# Set name of the experiment\n",
    "config.name = 'p_tuning'\n",
    "config.exp_manager.resume_if_exists = False\n",
    "# Init the experiment manager and view the exp_dir\n",
    "exp_dir = exp_manager(trainer, config.get(\"exp_manager\", None))\n",
    "exp_dir = str(exp_dir)\n",
    "print(exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e24b6",
   "metadata": {},
   "source": [
    "Set the learning rate and the precision values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed4e2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some of the learning parameters\n",
    "config.model.optim.lr = 1e-4\n",
    "config.model.precision = config.trainer.precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3aa91",
   "metadata": {},
   "source": [
    "## P-Tuning Session\n",
    "\n",
    "The only thing left is to load up the model and begin p-tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7108855b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:17:53 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:17:53 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:18:32 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-11-17 09:18:32 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "[NeMo I 2023-11-17 09:18:32 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:18:33 megatron_base_model:264] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2023-11-17 09:18:35 nlp_overrides:401] Model MegatronGPTModel was successfully restored from /workspace/source_code/nemo_gpt1.3B_fp16.nemo.\n",
      "[NeMo I 2023-11-17 09:18:35 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:19:15 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-11-17 09:19:15 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-11-17 09:19:15 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "[NeMo I 2023-11-17 09:19:15 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:19:15 megatron_base_model:264] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2023-11-17 09:19:17 nlp_overrides:401] Model MegatronGPTModel was successfully restored from /workspace/source_code/nemo_gpt1.3B_fp16.nemo.\n",
      "[NeMo I 2023-11-17 09:19:17 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.nlp.models.language_modeling.megatron_gpt_prompt_learning_model import MegatronGPTPromptLearningModel\n",
    "\n",
    "model = MegatronGPTPromptLearningModel(cfg=config.model,trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a56de13",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "[NeMo I 2023-07-08 00:24:45 megatron_init:225] Rank 0 has data parallel group: [0]\n",
    "[NeMo I 2023-07-08 00:24:45 megatron_init:228] All data parallel group ranks: [[0]]\n",
    "[NeMo I 2023-07-08 00:24:45 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
    "[NeMo I 2023-07-08 00:24:45 megatron_init:237] Rank 0 has model parallel group: [0]\n",
    "[NeMo I 2023-07-08 00:24:45 megatron_init:238] All model parallel group ranks: [[0]]\n",
    "...\n",
    "[NeMo I 2023-07-08 00:24:50 megatron_base_model:205] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
    "[NeMo I 2023-07-08 02:38:42 nlp_overrides:374] Model MegatronGPTModel was successfully restored from /workspace/results/multitask_ptuning/megatron_gpt_345m.nemo.\n",
    "[NeMo I 2023-07-08 02:38:42 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.\n",
    "Using pad_token, but it is not set yet.\n",
    "Using mask_token, but it is not set yet.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c521374",
   "metadata": {},
   "source": [
    "Note: Each training epoch takes around 7 mins but may vary based on the device used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53334bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-11-17 09:19:52 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:175: UserWarning: The `batch_idx` argument in `MegatronGPTPromptLearningModel.on_train_batch_start` hook may not match with the actual batch index when using a `dataloader_iter` argument in your `training_step`.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "[NeMo W 2023-11-17 09:19:52 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:175: UserWarning: The `batch_idx` argument in `MegatronGPTPromptLearningModel.on_train_batch_end` hook may not match with the actual batch index when using a `dataloader_iter` argument in your `training_step`.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "[NeMo W 2023-11-17 09:19:52 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/lightning_fabric/plugins/environments/torchelastic.py:36: UserWarning: MASTER_ADDR environment variable is not defined. Set as localhost\n",
      "      rank_zero_warn(\"MASTER_ADDR environment variable is not defined. Set as localhost\")\n",
      "    \n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d20eb43faf4265bfc56d01e69efc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:19:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:20:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:21:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:22:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046e0f1d379a48cc8d42237488175fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2023-11-17 09:23:33 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-9c74b95c-1807-52fd-95c2-373b3bf5b177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:23:33 nlp_overrides:124] Configuring DDP for model parallelism.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-11-17 09:23:33 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:82.)\n",
      "      self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:23:33 modelPT:721] Optimizer config = FusedAdam (\n",
      "    Parameter Group 0\n",
      "        betas: [0.9, 0.98]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2023-11-17 09:23:33 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x1553c6f44490>\" \n",
      "    will be used during training (effective maximum steps = 3750) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    max_steps: 3750\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type                   | Params\n",
      "-----------------------------------------------------------\n",
      "0 | frozen_model    | MegatronGPTModel       | 812 M \n",
      "1 | word_embeddings | VocabParallelEmbedding | 103 M \n",
      "2 | prompt_encoder  | PromptEncoder          | 8.5 M \n",
      "-----------------------------------------------------------\n",
      "8.4 M     Trainable params\n",
      "812 M     Non-trainable params\n",
      "820 M     Total params\n",
      "1,641.669 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911e3502fc7542309a41f0958f96a855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-11-17 09:23:34 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:401: UserWarning: Found `dataloader_iter` argument in the `validation_step`. Note that the support for this signature is experimental and the behavior is subject to change.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "[NeMo W 2023-11-17 09:23:34 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:23:36 megatron_gpt_prompt_learning_model:440] val_loss: 2.6965432167053223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-11-17 09:23:36 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2023-11-17 09:23:36 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:344: UserWarning: Found `dataloader_iter` argument in the `training_step`. Note that the support for this signature is experimental and the behavior is subject to change.\n",
      "      rank_zero_warn(\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fe3bdb5ed24a258fd224415a16ecd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-11-17 09:23:39 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2023-11-17 09:23:39 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "      warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb95dab61f244e99001ac09766f107e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:27:33 megatron_gpt_prompt_learning_model:440] val_loss: 1.6016062498092651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 750: 'val_loss' reached 1.60161 (best 1.60161), saving model to '/workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-17_09-17-46/checkpoints/megatron_gpt_prompt_tune--val_loss=1.602-step=750.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:27:34 nemo_model_checkpoint:168] New best .nemo model saved to: /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-17_09-17-46/checkpoints/p_tuning.nemo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b619c51dfe74617af9fdff78ff49dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:31:28 megatron_gpt_prompt_learning_model:440] val_loss: 1.565399169921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1500: 'val_loss' reached 1.56540 (best 1.56540), saving model to '/workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-17_09-17-46/checkpoints/megatron_gpt_prompt_tune--val_loss=1.565-step=1500.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-17 09:31:29 nemo_model_checkpoint:168] New best .nemo model saved to: /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-17_09-17-46/checkpoints/p_tuning.nemo\n",
      "[NeMo I 2023-11-17 09:31:29 nlp_overrides:231] Removing checkpoint: /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-17_09-17-46/checkpoints/megatron_gpt_prompt_tune--val_loss=1.602-step=750-last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.036 >= min_delta = 0.001. New best score: 1.565\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a3f68",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
    "----------------------------------------------------------------------------------------------------\n",
    "distributed_backend=nccl\n",
    "All distributed processes registered. Starting with 1 processes\n",
    "----------------------------------------------------------------------------------------------------\n",
    "...\n",
    "[NeMo I 2023-08-17 02:38:46 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n",
    "0it [00:00, ?it/s]\n",
    "[NeMo I 2023-08-17 02:38:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
    "[NeMo I 2023-08-17 02:38:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
    "[NeMo I 2023-08-17 02:38:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
    "...\n",
    "\n",
    "Validation: 0it [00:00, ?it/s]\n",
    "\n",
    "[NeMo I 2023-08-17 03:01:38 megatron_gpt_prompt_learning_model:391] val_loss: 1.7857784032821655\n",
    "Epoch 0, global step 3016: 'val_loss' reached 1.78578 (best 1.78578), saving model to '/workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-08-17_02-38-32/checkpoints/megatron_gpt_prompt_tune--val_loss=1.786-step=3016.ckpt' as top 2\n",
    "[NeMo I 2023-08-17 03:01:38 exp_manager:963] New best .nemo model saved to: /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-08-17_02-38-32/checkpoints/p_tuning.nemo\n",
    "Metric val_loss improved. New best score: 1.786\n",
    "...\n",
    "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
    "[NeMo I 2023-08-17 06:37:43 exp_manager:963] New best .nemo model saved to: /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-08-17_02-38-32/checkpoints/p_tuning.nemo\n",
    "Restoring states from the checkpoint path at /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-08-17_02-38-32/checkpoints/megatron_gpt_prompt_tune--val_loss=1.596-step=63336.ckpt\n",
    "Restored all states from the checkpoint file at /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-08-17_02-38-32/checkpoints/megatron_gpt_prompt_tune--val_loss=1.596-step=63336.ckpt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdfc947",
   "metadata": {},
   "source": [
    "## Inference After P-Tuning\n",
    "\n",
    "- Restore the Megatron-GPT Prompt Learning Model from the specified checkpoint path by `trainer.fit(model)` output above `eg:'/workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-08-17_02-38-32/checkpoints/p_tuning.nemo'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186a224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# modify the restore_path to the path specified in the trainer.fit(model) output\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "mymodel = nemo_nlp.models.language_modeling.megatron_gpt_prompt_learning_model.MegatronGPTPromptLearningModel.restore_from(restore_path='/workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-13_06-54-54/checkpoints/p_tuning.nemo',trainer=trainer)\n",
    "# You can perform inference using this restored model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd66b6",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "[NeMo I 2023-08-17 19:35:59 megatron_init:225] Rank 0 has data parallel group: [0]\n",
    "[NeMo I 2023-08-17 19:35:59 megatron_init:228] All data parallel group ranks: [[0]]\n",
    "[NeMo I 2023-08-17 19:35:59 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
    "[NeMo I 2023-08-17 19:35:59 megatron_init:237] Rank 0 has model parallel group: [0]\n",
    "...\n",
    "[NeMo I 2023-08-17 19:36:04 megatron_base_model:205] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
    "[NeMo I 2023-08-17 19:36:05 nlp_overrides:374] Model MegatronGPTModel was successfully restored from /workspace/results/multitask_ptuning/megatron_gpt_345m.nemo.\n",
    "[NeMo I 2023-08-17 19:36:05 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.\n",
    "Using pad_token, but it is not set yet.\n",
    "Using mask_token, but it is not set yet.\n",
    "[NeMo I 2023-08-17 19:36:05 save_restore_connector:247] Model MegatronGPTPromptLearningModel was successfully restored from /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-08-17_02-38-32/checkpoints/p_tuning.nemo.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de8f96",
   "metadata": {},
   "source": [
    "### Run the inference using the test examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80453c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = [\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Document Name\" that should be reviewed by a lawyer. Details: The name of the contract'},\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Agreement Date\" that should be reviewed by a lawyer. Details: The date of the contract'},\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Effective Date\" that should be reviewed by a lawyer. Details: The date when the contract is effective\\xa0'},\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Expiration Date\" that should be reviewed by a lawyer. Details: On what date will the contract\\'s initial term expire?'},\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Governing Law\" that should be reviewed by a lawyer. Details: Which state/country\\'s law governs the interpretation of the contract?'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff3357",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = mymodel.generate(inputs=test_examples, length_params=None)\n",
    "print('The prediction results:\\n')\n",
    "for response in responses['sentences']:\n",
    "    parts = response.split(\"Answer:\", 1)\n",
    "    if len(parts) > 1:\n",
    "        answer = parts[1].strip()\n",
    "        print(answer)\n",
    "    else:\n",
    "        print(\"No answer found\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c0705",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "```python\n",
    "[NeMo I 2023-08-17 19:36:12 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n",
    "  0%|          | 0/5 [00:00<?, ?it/s]\n",
    "[NeMo I 2023-08-17 19:36:12 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
    "The prediction results:\n",
    "\n",
    "SPONSORSHIP AGREEMENT\n",
    "------------------------------\n",
    "January 1, 2010\n",
    "------------------------------\n",
    "January 1, 2010\n",
    "------------------------------\n",
    "This Agreement shall commence on  January 1, 2010 and extend through December 31, 2010.\n",
    "------------------------------\n",
    "This Agreement shall be governed by and construed in accordance with the laws of the State of Texas without regard to conflicts of laws principles.\n",
    "------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c67f0",
   "metadata": {},
   "source": [
    "## Multi-task Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6408ae2a",
   "metadata": {},
   "source": [
    "This section will dive into multi-task inference using prompt-tuned language models. These models are versatile because they've learned from various prompts during training, enabling them to handle different tasks effectively. The process eliminates the need for separate fine-tuning per task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8a971",
   "metadata": {},
   "source": [
    "#### Preparing for Multi-Task Inference:\n",
    "To perform multi-task inference using prompt-tuned models, you need to have the following components ready:\n",
    "\n",
    "- A prompt-tuned model saved in a .nemo file format (virtual_prompt_model_file).\n",
    "- A pretrained GPT model in .nemo file format (gpt_model_file)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523e4d8",
   "metadata": {},
   "source": [
    "The inference file can contain a mix of prompts from all the tasks the model has been prompt tuned on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53a57f",
   "metadata": {},
   "source": [
    "```python\n",
    "python megatron_gpt_prompt_learning_eval.py \\\n",
    "            virtual_prompt_model_file=PATH_TO_NEMO_PROMPT_LEARNING_MODEL_FILE \\\n",
    "            gpt_model_file=PATH_TO_FROZEN_GPT_MODEL_FILE \\\n",
    "            inference.greedy=True \\\n",
    "            inference.add_BOS=False \\\n",
    "            trainer.devices=1 \\\n",
    "            trainer.num_nodes=1 \\\n",
    "            tensor_model_parallel_size=1 \\\n",
    "            pipeline_model_parallel_size=1 \\\n",
    "            pred_file_path=PATH_WHERE_PRED_TEXT_FILE_WILL_BE_SAVED \\\n",
    "            data_paths=[path/to/dataset1.jsonl, path/to/dataset2.jsonl]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abdadd",
   "metadata": {},
   "source": [
    "virtual_prompt_model_file should be a path to a .nemo file saved after p-tuning/prompt tuning, and gpt_model_file is still the path to the gpt model’s .nemo file.\n",
    "\n",
    "data_paths should be a list of .json or .jsonl files containing JSON objects similar to the ones used during prompt learning. They should have keys that match the fields specified in the prompt template. Fields can be dropped from the prompt dictionary, and their corresponding section of the prompt template will be automatically removed.\n",
    "\n",
    "Generally, prompt learning inference is like running inference with a GPT model. The only difference is you need to add \n",
    "`virtual_prompt_model_file=PATH_TO_NEMO_PROMPT_LEARNING_MODEL_FILE` to your command if you're using a p-tuned/prompt-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703cffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define the path to the predictions folder and the predictions file\n",
    "predictions_folder = \"/workspace/results/activity2/predictions\"\n",
    "predictions_file = \"cuad_predictions.txt\"\n",
    "predictions_path = os.path.join(predictions_folder, predictions_file)\n",
    "\n",
    "# Check if the predictions folder exists, and create it if not\n",
    "if not os.path.exists(predictions_folder):\n",
    "    os.makedirs(predictions_folder)\n",
    "\n",
    "# Check if the predictions file already exists\n",
    "if not os.path.exists(predictions_path):\n",
    "    # If it doesn't exist, create an empty file\n",
    "    with open(predictions_path, 'w') as f:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8dc688",
   "metadata": {},
   "source": [
    "When running the cell below, you can experience the error:`errno: 98 - Address already in use`\n",
    "\n",
    "```python\n",
    "...\n",
    "[NeMo I 2023-11-03 18:35:44 save_restore_connector:249] Model MegatronGPTPromptLearningModel was successfully restored from /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-03_14-50-49/checkpoints/p_tuning.nemo.\n",
    "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
    "[W socket.cpp:426] [c10d] The server socket has failed to bind to [::]:53394 (errno: 98 - Address already in use).\n",
    "[W socket.cpp:426] [c10d] The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).\n",
    "[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.\n",
    "Error executing job with overrides: ['virtual_prompt_model_file=/workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-03_14-50-49/checkpoints/p_tuning.nemo', 'gpt_model_file=/workspace/source_code/nemo_gpt1.3B_fp16.nemo', 'inference.greedy=True', 'inference.add_BOS=False', 'trainer.devices=1', 'trainer.num_nodes=1', 'tensor_model_parallel_size=1', 'pipeline_model_parallel_size=1', 'pred_file_path=/workspace/results/challenge_ptuning/predictions/cuad_predictions.txt', 'data_paths=[/workspace/data/cuad/cuad_short_test.jsonl]']\n",
    "Traceback (most recent call last):\n",
    "  File \"/workspace/source_code/challenge_ptuning/megatron_gpt_prompt_learning_eval.py\", line 121, in main\n",
    "    model.trainer.strategy.setup_environment()\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 152, in setup_environment\n",
    "    self.setup_distributed()\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/nemo/collections/nlp/parts/nlp_overrides.py\", line 100, in setup_distributed\n",
    "    super().setup_distributed()\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 203, in setup_distributed\n",
    "    _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/distributed.py\", line 245, in _init_dist_connection\n",
    "    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 145, in wrapper\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 1025, in init_process_group\n",
    "    store, rank, world_size = next(rendezvous_iterator)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 245, in _env_rendezvous_handler\n",
    "    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 176, in _create_c10d_store\n",
    "    return TCPStore(\n",
    "RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:53394 (errno: 98 - Address already in use). The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).\n",
    "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
    "\n",
    "```\n",
    "\n",
    "The solution is to shut down the kernel of all opened notebooks and close them, including the Jupyter notebook terminal (if opened), to avoid the error below. When you restart this notebook's kernel, you do not need to run the notebook from the start; please continue running from the same cell.\n",
    "\n",
    "Run greedy inference from a p-tuned/prompt-tuned model's nemo file by setting the path for `virtual_prompt_model_file` and `gpt_model_file` (remember to update this part- `/2023-10-20_08-11-09/` for the `virtual_prompt_model_file`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d09a027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python /workspace/source_code/activity2/megatron_gpt_prompt_learning_eval.py \\\n",
    "            virtual_prompt_model_file=\"/workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-13_06-54-54/checkpoints/p_tuning.nemo\" \\\n",
    "            gpt_model_file=\"/workspace/source_code/nemo_gpt1.3B_fp16.nemo\" \\\n",
    "            inference.greedy=True \\\n",
    "            inference.add_BOS=False \\\n",
    "            trainer.devices=1 \\\n",
    "            trainer.num_nodes=1 \\\n",
    "            tensor_model_parallel_size=1 \\\n",
    "            pipeline_model_parallel_size=1 \\\n",
    "            pred_file_path=\"/workspace/results/activity2/predictions/cuad_predictions.txt\"\\\n",
    "            data_paths=[\"/workspace/data/cuad/cuad_short_test.jsonl\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006f8dd",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "\n",
    "...\n",
    "Predicting DataLoader 0:   0%|                         | 0/2091 [00:00<?, ?it/s][NeMo W 2023-08-17 19:44:56 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
    "      warnings.warn(\"This function is only for unittest\")\n",
    "    \n",
    "Predicting DataLoader 0: 100%|██████████████| 2091/2091 [25:39<00:00,  1.36it/s]\n",
    "***************************\n",
    "Inference Complete, prediction file saved at /workspace/results/multitask_ptuning/predictions/cuad_predictions.txt\n",
    "***************************\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b3302",
   "metadata": {},
   "source": [
    "#### Predicted Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the text file with predicted answers\n",
    "predicted_answers = []\n",
    "with open(\"/workspace/results/activity2/predictions/cuad_predictions.txt\", \"r\") as txt_file:\n",
    "    predicted_answers = [line.strip() for line in txt_file]\n",
    "\n",
    "# load the predicted answers\n",
    "for i in range(len(predicted_answers)):   \n",
    "    predicted_answer = predicted_answers[i]\n",
    "\n",
    "    # Extract the \"Answer:\" portion from the predicted answer line\n",
    "    predicted_answer_text = predicted_answer.split(\"Answer:\", 1)[-1].strip()\n",
    "\n",
    "    print(f\"Question {i+1} \")\n",
    "    print(f\"Predicted Answer: {predicted_answer_text}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f7cfc",
   "metadata": {},
   "source": [
    "#### Check Your Output Against the Grundtruth \n",
    "\n",
    "**Context 1:** In 2010 the Amazon rainforest experienced another severe drought, in some ways more extreme than the 2005 drought. The affected region was approximately 1,160,000 square miles (3,000,000 km2) of rainforest, compared to 734,000 square miles (1,900,000 km2) in 2005. The 2010 drought had three epicenters where vegetation died off, whereas in 2005 the drought was focused on the southwestern part. The findings were published in the journal Science. In a typical year the Amazon absorbs 1.5 gigatons of carbon dioxide; during 2005 instead 5 gigatons were released and in 2010 8 gigatons were released.\n",
    "\n",
    "**Context 2:** The sun is a massive ball of hot, glowing gases at the center of our solar system. It provides light, heat, and energy that sustains life on Earth. The sun's surface temperature is around 5,500 degrees Celsius (9,932 degrees Fahrenheit), while its core temperature reaches about 15 million degrees Celsius (27 million degrees Fahrenheit). The sun's energy is generated through a process called nuclear fusion, where hydrogen atoms combine to form helium, releasing immense amounts of energy in the process.\n",
    "\n",
    "|Sn|Questions|Expected Answers|\n",
    "|-|-|-|\n",
    "|1|How many gigatons of carbon are absorbed by the Amazon in a typical year?|In a typical year the Amazon absorbs 1.5 gigatons of carbon dioxide|\n",
    "|2|In 2010 the affected region by the drought was approximately?|The affected region was approximately 1,160,000 square miles (3,000,000 km2) of rainforest|\n",
    "|3|Where were the findings regarding the droughts published in?|The findings were published in the journal Science|\n",
    "|4|What is the approximate surface temperature of the sun?|The sun's surface temperature is around 5,500 degrees Celsius (9,932 degrees Fahrenheit)|\n",
    "|5|How does the sun generate its energy?|The sun's energy is generated through a process called nuclear fusion, where hydrogen atoms combine to form helium, releasing immense amounts of energy in the process.|\n",
    "|6|What process is responsible for the sun's energy generation, where hydrogen atoms combine to form helium?|The process called nuclear fusion.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380392eb",
   "metadata": {},
   "source": [
    "---\n",
    "### Resources\n",
    "Below are resourceful links to guide you and assist you in learning more.\n",
    "- [NeMo Models](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/core.html)\n",
    "- [Core APIs](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/api.html)\n",
    "- [Experiment Manager](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/exp_manager.html)\n",
    "- [Exporting NeMo Models](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/export.html)\n",
    "- [Prompt Learning](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/nemo_megatron/prompt_learning.html)\n",
    "- [NeMo Megatron API](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/api.html)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dee888",
   "metadata": {},
   "source": [
    "\n",
    "## Licensing\n",
    "Copyright © 2022 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
