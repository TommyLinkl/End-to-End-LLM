{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Prompt Context\n",
    "\n",
    "This example shows how you can include custom data in your custom prompt.\n",
    "\n",
    "A common use case is to let the LLM know the current date and time so that it can respond appropriately to user queries involving a time component, e.g., \"What day is today?\". To achieve this, you need to:\n",
    "\n",
    "1. Register an additional [prompt context variable](../../docs/user_guide/advanced/prompt-customization.md#prompt-variables) (i.e., an additional variable that will be available when the prompts are rendered). This can be achieved using the `register_prompt_context(name, value_or_fn)`.\n",
    "\n",
    "2. Change the desired prompts to include the new variable(s).\n",
    "\n",
    "Check out the `config.py` and `config.yml` files for a proof-of-concept.\n",
    "\n",
    "You can test this configuration with `nemoguardrails chat --config=examples/custom_prompt_context`.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
